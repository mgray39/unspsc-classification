{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be079a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb55c408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-11 11:02:03.525 ip-172-16-68-51.ec2.internal:24766 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-09-11 11:02:03.722 ip-172-16-68-51.ec2.internal:24766 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291b89dc73dc4891b2c57b2424ba91f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3610eecf632540a598c0563caa511be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f40f22e587b49c99051705e19903f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import smdebug.pytorch as smd\n",
    "from smdebug import modes\n",
    "from smdebug.pytorch import get_hook\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "#distilbert tokenizer - distilbert uncased\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad6e1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e57f46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "def prepare_string(string, tokenizer, MAX_LEN):\n",
    "    \n",
    "    input_ids = list(tokenizer(string)['input_ids'])\n",
    "    \n",
    "    input_ids_padded = []\n",
    "    while len(input_ids) < MAX_LEN:\n",
    "        input_ids.append(0)\n",
    "    \n",
    "    # attention mask is 0 where length is padded, otherwise it is 1\n",
    "    \n",
    "    att_mask = [int(id_ > 0) for id_ in input_ids]\n",
    "    \n",
    "    # convert to PyTorch data types.\n",
    "    test_inputs = torch.tensor(input_ids)\n",
    "    test_masks = torch.tensor(att_mask)\n",
    "    \n",
    "    return {'input_ids': test_inputs, 'attention_mask': test_masks}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb1502a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(input_str: str) -> str:\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    \n",
    "    return only_ascii.decode()\n",
    "\n",
    "\n",
    "def string_cleaning(string_series: pd.Series) -> pd.Series:\n",
    "    \n",
    "    clean_series = (string_series\n",
    "                    .astype(str)\n",
    "                    .str.replace('[^\\w\\s]',' ', regex=True)\n",
    "                    .str.replace('\\n', ' ')\n",
    "                    .str.replace(r'[\\s+]', ' ', regex=True)\n",
    "                    .apply(remove_accents))\n",
    "    \n",
    "    return clean_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9fc699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StringIO('{\"description\": [\"this is a string\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09b0dd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.StringIO at 0x7f554b9f69d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "111232aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_json(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db4b1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (df\n",
    "     .assign(description = lambda df: string_cleaning(df['description'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1427e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_string(string, tokenizer, MAX_LEN):\n",
    "    \n",
    "    input_ids = list(tokenizer(string)['input_ids'])\n",
    "    \n",
    "    input_ids_padded = []\n",
    "    while len(input_ids) < MAX_LEN:\n",
    "        input_ids.append(0)\n",
    "    \n",
    "    # attention mask is 0 where length is padded, otherwise it is 1\n",
    "    \n",
    "    att_mask = [int(id_ > 0) for id_ in input_ids]\n",
    "    \n",
    "    # convert to PyTorch data types.\n",
    "    test_inputs = torch.tensor(input_ids)\n",
    "    test_masks = torch.tensor(att_mask)\n",
    "    \n",
    "    return {'input_ids': test_inputs, 'attention_mask': test_masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92e09e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 2023, 2003, 1037, 5164,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_string(b.iloc[0,0], tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ece6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.StringIO at 0x7f554b6619d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'this is a duck'\n",
    "\n",
    "StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb37a956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 9457, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7900ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
